# Lecture 2

Title: Image Classification
slide: http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture2.pdf

# Image Classification

## Image Classification 이란?

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled.png)

Image Classificaion이란 **입력 이미지를 받고, 미리 정해 놓은 카테고리 집합에서 어떤 카테고리에 속할지 고르는 것**이다. 

인간의 시각 체계는 고도화 되어 있기 때문에 이런 분류가 매우 쉽지만 컴퓨터는 이미지를 볼 때 숫자 집합과 픽셀 값으로만 보기 때문에 분류하기 어렵다. 고양이 사진을 예를 들어보면, 이미지에 아주 미묘한 변화만 주더라도 픽셀 값들은 완전히 변하게 된다. 카메라를 아주 조금 옆으로 옮기거나 조명에 따라서, 고양이가 취하고 있는 자세에 따라, 다른 것들에 의해 고양이가 가려지(occlusion)는 상황에 의해, 배경과 비슷한 이미지가 경우(Background clutter)에도 이 이미지가 고양이라는 것을 알 수 있어야 하며, 하나의 고양이 카테고리에서 다르게 생긴 고양이를 인식해야 한다.  

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%201.png)

사람들은 컴퓨터가 동물들을 인식하기 위해 고급 coded rules을 만들고자 하는 시도를 해왔고, Hubel과 Wiesel의 연구 덕분에 Eedges가 대단히 중요하다는 것도 알게 되었다. 그래서 우선 이미지에서 edges를 계산하고, 다양한 Corners와 Edges를 각 카테고리로 분류하는 방법을 적용했다. 

가령 세 개의 선이 만나는 지점이면 corner라고 했을 때 귀는 "여기에 corner 하나" "저기에도 corner 하나” 또 "저기에도 corner 하나" 가 있고 이런 방식으로 고양이 인식을 위해 "명시적인 규칙 집합"을 써내려 가는 방법이다. 하지만 이런 방식은 잘 동작하지 않았는데, 이런 알고리즘은 강인하지 못하고 카테고리 별로 모델을 만들어야 하는 등 확장성이 전혀 없는 방법이기 때문이다.

## Classifier 알고리즘

### **Data-driven approach**

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%202.png)

하나의 Insight는 바로 데이터 중심 접근 방법(Data-Driven Approcach) 이다. 객체들의 특징을 손으로 써내려 하는 것 대신에, 인터넷에 접속해서 엄청 많은 고양이/비행기/사슴 데이터를 수집하고, 이 데이터 셋들을 이용해서 Machine Learning Clssifier 를 학습 시키는 방법이다. 

입력 이미지를 고양이로 인식하려면 하나는 Train함수로 입력은 이미지와 레이블이고 출력은 모델이되고, 다른 하나는 Predict 함수로 입력이 모델이고, 출력은 이미지의 예측 값이 된다.

### Nearest neighbor

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%203.png)

Data-driven Approach로서 아주 좋은 알고리즘 중 하나는 Nearest neighbor이다. NN은 Train Step에서는 아무 일도 하지 않고, 단지 모든 학습 데이터를 기억한다. 그리고 Predict Step에서 새로운 이미지가 들어오면 새로운 이미지와 기존의 학습 데이터를 비교해서 가장 유사한 이미지로 레이블링을 예측한다. 

예시(CIFAR-10 데이터 셋)

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%204.png)

CIFAR-10 데이터 셋을 이용한 NN예제를 살펴보면, CIFAR-10에는 50,000여개의 트레이닝 샘플이 있고 각 이미지는 32x32 픽셀을 가진 3채널 컬러 이미지 셋이다. 이 이미지에 NN 알고리즘을 적용하면 트레이닝 셋에서 "가장 가까운 샘플"을 찾게 된다.  오른쪽 칸의 맨 왼쪽 열은 CIFAR-10 테스트 이미지이고, 그 오른쪽에는 학습 이미지 중 테스트 이미지와 유사한 순으로 정렬했다. 두 번째 행의 이미지는 개이고 가장 가까운 이미지(1등)도 개이다. 하지만 2등, 3등을 살펴보면 "사슴"이나 "말"같아 보이는 이미지들이 위치하고 있다. 

L1 Distance

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%205.png)

테스트 이미지를 학습 이미지들과 비교할 때 여러가지 비교 방법들이 있다. 앞선 예제에서는 L1 Distance(Manhattan distance)를 사용했다. 만약 4x4 테스트 이미지가 있다면, 테스트/트레이닝 이미지의 같은 자리의 픽셀을 서로 빼고 절댓값을 취한 후, 모든 픽셀의 수행 결과를 모두 더한다. 

NN의 경우 Train 함수가 단지 학습 데이터를 기억하기 때문에 상당히 단순하다. Test 함수에서는 이미지를 입력으로 받고 L1 Distance로 비교하여 학습 데이터들 중 테스트 이미지와 가장 유사한 이미지들을 찾아낸다. 

학습 속도

Train set의 이미지가 총 N개라면 Train/Test 함수의 속도는 어떻게 될까? Train time은 데이터를 기억만 하면 되기 때문에 상수 시간 O(1)이다. 하지만 Test time에서는 N개의 학습 데이터 전부를 테스트 이미지와 비교해야 하기 때문에 상당히 오래 걸린다. 따라서 **Train TIme < Test  TIme**이므로 상당히 "뒤집어진" 것이라 할 수 있다. 실제로 우리는 Train Time은 조금 느려도 되지만 Test Time에서는 빠르게 동작하길 원한다. CNN 같은 parametic model들은 NN과는 정 반대로, Train TIme은 엄청 오래 걸리지만 Test Time은 엄청 빠르다.

문제점

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%206.png)

위의 그림은 NN의 "decision regions" 을 그린 것이다. 2차원 평면 상의 각 점은 학습 데이터이고, 점의 색은 클래스 레이블(카테고리)이다. 이 예제에서는 클래스가 5개이다. 2차원 평면 내의 모든 좌표에서 각 좌표가 어떤 학습 데이터와 가장 가까운지 계산하여 각 좌표를 해당 클래스로 칠했다. NN 분류기는 공간을 나눠서 각 레이블로 분류하는데, 성능은 별로 좋지 않다. 

가운데를 보면, 대부분이 초록색 점들인데 중간에 노란 점이 끼어있다. NN 알고리즘은 "가장 가까운 이웃" 만을 보기 때문에, 녹색 무리 한 가운데 노란색 영역이 생겨 버린다. 그리고 이와 유사하게 초록색 영역이 파란색 영역을 침범하고 있다. 이 또한 초록색 점이 끼어들어서 그렇다. 이러한 문제들로 인해 NN의 조금 더 일반화된 버전인 k-NN 알고리즘이 탄생하였다.

### k-Nearest neighbor

k-NN은 단순하게 가장 가까운 이웃만 찾기보다는 Distance metric을 이용해서 가까운 이웃을 K개의 만큼 찾고, 이웃끼리 투표를 하여 가장 많은 득표 수를 획득한 레이블로 예측한다. 투표를 하는 방법은 거리별 가중치를 고려하는 등 다양하고 복잡한 방법들이 있다. 그러나 여기서는 가장 잘 동작하면서도 가장 쉬운 “득표 수만 고려하는 방법”을 살펴보겠다. 

k의 갯수

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%207.png)

세 예제는 동일한 데이터를 사용한 k-nn 분류기들이다. 먼저 K=3 의 경우를 살펴보면, 앞서 초록색 영역에 자리 잡았던 노란색 점 때문에 생긴 노란 지역이 깔끔하게 사라졌다. 그리고 왼쪽의 빨강/파랑 사이의 뾰족한 경계들도 점차 부드러워지고 있다. K=5의 경우를 살펴보면, 파란/빨간 영역의 경계가 이제는 아주 부드럽고 좋아졌다. 대게 NN분류기를 사용하면 K가 1보다 커야 결정 경계가 더 부드러워지고 더 좋은 결과를 보이기 때문에 K는 적어도 1보다는 큰 값으로 사용한다. K값을 높히면 더 많은 이웃들이 투표에 참여하면서 각종 잡음에 조금 더 강인진다. 

거리 척도(L1/L2)

k-nn을 사용할 때 결정해야 할 한 가지 사항이 더 있는데, 바로 서로 다른 점들을 어떻게 비교할 것인지이다. 지금까지는 L1 Distance 즉, "픽셀 간 차이 절대값의 합"을 이용해서 계산했다. 또다른 방법으로는 L2, 즉 Euclidean distance 즉, "제곱 합의 제곱근"을 거리로 이용하는 방법이 있다. 서로 다른 척도에서는 해당 공간의 근본적인 기하학적 구조 자체가 서로 다르기 때문에 어떤 "거리 척도(distance metric)" 을 선택할지도 아주 흥미로운 주제이다. 

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%208.png)

왼쪽에 보이는 사각형은 사실 L1 Distance의 관점에서는 원이다. L1의 관점에서는 사각형 위의 점들이 모두 원점으로부터 동일한 거리만큼 떨어져 있다. 오른쪽은 L2, Euclidean distance 의 관점에서의 원이다. L1은 어떤 좌표 시스템이냐에 따라 많은 영향을 받는다. 가령 기존의 좌표계를 회전시키면 L1 distance는 변하지만, L2 Distance의 경우에는 아무 변화가 없다. 만약 특징 벡터의 각각 요소들이 개별적인 의미를 가지고 있다면(e.g. 키 몸무게) L1 Distance가 더 잘 어울릴 수 있고, 특징 벡터가 일반적인 벡터이고 **요소들간의 실질적인 의미를 잘 모르는 경우라면 L2 Distance가 조금 더 잘 어울릴 수 있다.** 

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%209.png)

양 쪽 모두 동일한 데이터이지만, 왼쪽은 L1 Distance를 오른쪽은 L2 Distance를 사용했다. 결과를 보면 거리 척도에 따라서 결정 경계의 모양 자체가 달라짐을 알 수 있다. 왼쪽의 L1 Distance를 살펴보면 L1 Distance가 좌표 시스템의 영향을 받기 때문에 결정 경계가 "좌표 축"에 영향을 받는 경향이 있는 반면, L2 Distance는 좌표 축의 영향을 받지 않고 결정 경계를 만들기 때문에 조금 더 자연스럽다.

하이퍼 파라미터

하이퍼파라미터는 Train time에 학습하는 것이 아니고, **학습 전 사전에 반드시 선택해야만 한다.** 하이퍼 파라미터를 정하는 일은 문제의존적(problem-dependent)이다. 가장 간단한 방법은 데이터에 맞게 다양한 하이퍼파라미터 값을 시도해 보고 가장 좋은 값을 찾는 것이다. "다양한 하이퍼 파라미터를 시도해 보는 것" 과 "그중 최고를 선택하는 것" 이 무슨 뜻일까? 

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%2010.png)

첫 번째 아이디어는 "학습데이터의 정확도와 성능"를 최대화하는 하이퍼파라미터를 선택하는 것이다. 그러나 절대로 이렇게 해서는 안된다. K = 1 일 때가 항상 학습 데이터를 가장 완벽하게 분류하지만, 실제로는 K를 더 큰 값으로 선택하는 것이 학습 데이터에서는 몇 개 잘못 분류할 수는 있지만 학습 데이터에 없던 데이터에 대해서는 더 좋은 성능을 보일 수 있다. 우리의 목표는 완전히 새로운 데이터에서 잘 작동하는 것이다. 

두 번째 아이디어는 전체 데이터셋 중 학습 데이터를 쪼개서 일부를 테스트 데이터로 사용하는 것이다. 이 방법이 조금 더 합리적인 것 같지만 사실 이 또한 절대 하면 안된다. 학습 시킨 모델들 중 테스트 데이터에 가장 잘 맞는 모델을 선택한다면 우리는 그저 "테스트 셋에서만" 잘 동작하는 하이퍼파라미터를 고른 것이다. 테스트 셋에서의 성능은 한번도 보지 못한 데이터에서의 성능을 대표할 수는 없다. 

훨씬 더 일반적인 방법은 **데이터를 세 개로 나누는 것**이다. 데이터의 대부분은 트레이닝 셋으로 나누고, 일부는 밸리데이션 셋, 그리고 나머지는 테스트 셋으로 나눈다. 다양한 하이퍼파라미터로 "트레이닝 셋" 을 학습시킨 후. "벨리데이션 셋" 으로 검증을 한다. 벨리데이션 셋에서 가장 좋았던 하이퍼파라미터를 선택하여 테스트 셋에서는 "오로지 한번만" 수행한다.

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%2011.png)

또 다른 하이퍼파라미터 선택 전략은 크로스 벨리데이션(교차 검증) 이다. 사실 이 방법은 작은 데이터셋일 경우 많이 사용하고 딥러닝에서는 많이 사용하진 않는다. 이 아이디어는 우선 테스트 데이터를 정해 놓고 나머지 데이터는 트레이닝/벨리데이션으로 딱 나눠 놓는 대신에 트레이닝 데이터를 여러 부분으로 나눠준다. 이 예제에서는 5-Fold Cross Validation을 사용하였다. 처음 4개의 fold에서 하이퍼 파라미터를 학습시키고 남은 한 fold에서 알고리즘을 평가한다. 그리고 1,2,3,5 fold에서 다시 학습시키고 4 fold로 평가하여, 이런식으로 계속 순환하고 반복한다. 

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%2012.png)

X축은 K-NN의 K이고 Y축은 분류 정확도이다. 각 K마다 5번의 크로스 벨리데이션을 통해 알고리즘이 얼마나 잘 동작하는지를 알려준다. 현재 예시에서는 K = 7 일때 가장 성능이 좋다. 뿐만 아니라 여러 validation folds별 성능의 분산(variance)도 고려해 볼 수 있다. 분산을 같이 계산하게 되면 어떤 하이퍼파라미터가 가장 좋은지와 그 성능의 분산도 알 수 있다.

문제점

첫번째 문제점은 k-nn이 너무 느리다는 것이다. 다시 말해 test에서의 속도가 train에서의 속도보다 훨씬 느리다는 것이다. 또 하나의 문제는 L1/L2 Distance가 이미지간의 거리를 측정하기에 적절하지 않다는 점이다. 이 벡터간의 거리 측정 관련 함수들은(L1/L2) 이미지들 간의 "지각적 유사성"을 측정하는 척도로는 적절하지 않다.

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%2013.png)

마지막 문제점은 "차원의 저주"이다. K-NN이 하는 일은 트레이닝 데이터를 이용해서 공간을 분할하는 일이다. 이는 K-NN이 잘 동작하려면 전체 공간을 조밀하게 커버할 만큼의 충분한 트레이닝 샘플이 필요하다는 것을 의미한다. 공간을 조밀하게 덮으려면 충분한 양의 학습 데이터가 필요하고 그 양은 차원이 증가함에 따라 기하급수 적으로 증가한다. 고차원의 이미지라면 모든 공간을 조밀하게 메울만큼의 데이터를 모으는 일은 현실적으로 불가능하다.

위의 그림에서 각 점은 트레이닝 샘플들을 의미한다. 점 하나하나가 트레이닝 샘플이며, 각 점의 색은 트레이닝 샘플이 속한 카테고리를 나타낸다. 가령 맨 왼쪽의 1차원을 보시면 이 공간을 조밀하게 덮으려면 트레이닝 샘플 4개면 충분하지만, 2차원 공간을 다 덮으려면 16개가 필요하여 1차원의 4배가 필요하다.

### parametric approach

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%2014.png)

CIFAR-10은 50,000여개의 트레이닝 샘플이 있고 각 이미지는 32x32 픽셀을 가진 3채널 컬러 이미지셋이다. Linear classifier는 parametric model의 가장 단순한 형태이다. parametric model에는 두 개의 요소가 있는데, 입력 이미지와 파라미터(가중치)이다. 입력 이미지를 보통 "X" 로, 파라미터(가중치)는 "W"라고도 하고 세타(theta)라도고 한다. 함수는 data X와 parameter W를 가지고 CIFAR-10의 각 10개의 카테고리의 스코어를 출력한다. "고양이"의 스코어가 높다는 건 입력 X가 "고양이"일 확률이 크다는 것을 의미한다. 앞서 K-NN은 파라미터가 없었고, 모든 트레이닝 셋을 Test time에 사용했다. 그러나 parametric approach 에서는 트레이닝 데이터의 정보를 요약하여 요약된 정보를 파라미터 W에 모아준다. 이런 방식을 사용하면 Test time에서 더이상 트레이닝 데이터가 필요하지 않게 되고, Test time 처리 속도가 훨씬 빨라지게 된다. 

### Linear Classification

Linear Classification 아주 간단하고 중요한 NN과 CNN의 기반 알고리즘이다. 앞으로 학습할 다양한 종류의 딥러닝 알고리즘들의 가장 기본이 되는 것 중 하나이다.

예시(CIFAR-10 데이터 셋)

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%2015.png)

가중치 W와 데이터 X를 조합하는 가장 쉬운 방법은 이 두 가지를 곱하는 것이다. 이 방법이 바로 Linear classification이고, F(x,W) = Wx 이다. 예를 들어, 입력 이미지는 32 x 32 x 3 이고, 이 값을 길게 펴서 열 벡터로 만들면 3,072-dim 벡터가 된다. 3072-dim열 벡터가 10-classes 스코어가 되어야 하기 때문에 행렬 W는 10 x 3072가 되어야 하며. 이 둘을 곱하면 10-classes 스코어를 의미하는 10 x 1 짜리 하나의 열 벡터를 얻게 된다. 10-dim 열 벡터인 Bias term도 같이 더해주기도 한다. Bias term은 "데이터와 무관하게” 특정 클래스에 "우선권"을 부여한다.

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%2016.png)

예를 들어보면, 2x2 이미지이고 전체 4개의 픽셀이 있다. 이미지를 4-dim 열 벡터로 쭉 펴고, 클래스는 세가지 고양이, 개, 배이다. 이때, 가중치 행렬 W는 4x3 행렬이 되고, 3-dim bias 벡터가 있다. 고양이 스코어"는 입력 이미지의 픽셀 값들과 가중치 행렬을 내적한 값에 bias term을 더한 것이다.

Linear classification은 템플릿 매칭과 거의 유사하다. 가중치 행렬 W의 각 행은 각 이미지에 대한 템플릿으로 볼 수 있고, 그 행 벡터와 이미지의 열 벡터 간의 내적을 계산하는데, 여기에서 내적이란 결국 클래스 간 탬플릿의 유사도를 측정하는 것과 같으며, bias는 데이터 독립적으로 각 클래스에 scailing offsets을 더해주는 것이다.

문제점

![Untitled](Lecture%202%2073e36fa82af643d5806cf9be2f8d2660/Untitled%2017.png)

템플릿 매칭의 관점에서 Linear classification 해석해보면, Linear classifier는 클래스당 하나의 템플릿밖에 허용하지 않는 문제점이 생긴다. 즉, Linear classifier로는 Multimodal problem를 풀기 힘들다. 맨 오른쪽 이미지를 보면 파란색으로 표시된 세 개의 섬들이 있다. 그 밖의 빨간색은 전부 다른 카테고리에 속한다. Multimodal data라면 한 클레스가 다양한 공간에 분포할 수 있으며 이 문제는 Linear classifier로는 풀 수 없다.

Linear classifier을 이미지를 고차원 공간의 한 점으로 보는 또 다른 관점으로 해석할 수 있다. 각 이미지을 고차원 공간의 한 점이라고 생각해 보면, Linear classifier는 각 클래스를 구분시켜 주는 선형 결정 경계를 그어주는 역할을 한다. 예를 들어, Linear classifier는 파란색 선을 학습해서 비행기와 다른 클래스를 구분할 수 있다. 위의 사진 중 맨 왼쪽 그림은 두 개의 클래스를 가진 데이터 셋이다. 데이터셋에는 파랑/빨강 두 개의 카테고리가 있고, 파랑색 카테고리는 0보다 큰 픽셀이 홀수 개 인 경우이다. 이 데이터를 선 하나로 분류할 방법은 없다. 즉, 이또한 Linear classifie로는 풀기 힘든 문제이다. 이는 영상 내 동물이나 사람의 수가 홀/짝수 인지를 분류하는 문제이다. 홀/짝수를 분류하는 것과 같은 반전성 문제(parity problem)는 일반적으로 Linear classification으로 풀기 힘든 문제이다.